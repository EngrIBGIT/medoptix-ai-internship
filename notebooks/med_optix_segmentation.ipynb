{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install boto3\n",
    "%pip install psycopg2\n",
    "%pip install sqlalchemy\n",
    "%pip install dotenv\n",
    "\n",
    "\n",
    "%pip matplotlib\n",
    "%pip plotly\n",
    "%pip seaborn \n",
    "\n",
    "\n",
    "# Run this cell to install these packages\n",
    "# !pip install pandas boto3 sqlalchemy python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ea2e9",
   "metadata": {},
   "source": [
    "# <h2 align=\"center\">Data Input</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c510ed6",
   "metadata": {},
   "source": [
    "### Define a Function to Query & Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5408b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to fetch data from the database\n",
    "def get_db_connection():\n",
    "    db_url = (\n",
    "        f\"postgresql://{os.environ['DB_USER']}:{os.environ['DB_PASSWORD']}@\"\n",
    "        f\"{os.environ['DB_HOST']}:{os.environ['DB_PORT']}/{os.environ['DB_NAME']}\"\n",
    "    )\n",
    "    return create_engine(db_url)\n",
    "\n",
    "# Instantiate the database connection\n",
    "engine = get_db_connection()\n",
    "\n",
    "\n",
    "# Define query to fetch data from each table\n",
    "query_clinics = \"SELECT * FROM clinics;\"\n",
    "query_patients = \"SELECT * FROM patients;\"\n",
    "query_sessions = \"SELECT * FROM sessions;\"\n",
    "query_feedback = \"SELECT * FROM feedback;\"\n",
    "query_dropout_flags = \"SELECT * FROM dropout_flags;\"\n",
    "query_interventions = \"SELECT * FROM interventions;\"\n",
    "\n",
    "# Load data from each table into a DataFrame\n",
    "clinics_df = pd.read_sql(query_clinics, engine)\n",
    "patients_df = pd.read_sql(query_patients, engine)\n",
    "sessions_df = pd.read_sql(query_sessions, engine)\n",
    "feedback_df = pd.read_sql(query_feedback, engine)\n",
    "dropout_flags_df = pd.read_sql(query_dropout_flags, engine)\n",
    "interventions_df = pd.read_sql(query_interventions, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b125d28",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "- Create New features\n",
    "- Merge relevant datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0f7692",
   "metadata": {},
   "source": [
    "## NOTE: \n",
    "After the EDA, the data is pretty messy, hence we will:\n",
    "- define the `patients data and session data` and merge the data together followed by, \n",
    "- creating a pipeline (define numerical and categorical columns),\n",
    "- Then preprocessing the data before doing the clustering,\n",
    "- Then do the clustering,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b274932",
   "metadata": {},
   "source": [
    "## Patient Segmentation:\n",
    "To see which cluster each patient belong to, to see the behaviour of how each patient behave in each cluster\n",
    "\n",
    "### Steps:\n",
    "    - Define the patients(who they are i.e the features)\n",
    "    - Define patients sessions\n",
    "\n",
    "- Defining patients/sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2be6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define the sessions and the patients had in regards to the therapy (Extra Features Engineering) i.e The Dynamic dataset\n",
    "sess_agg = (\n",
    "    sessions_df\n",
    "    .sort_values(['patient_id', 'date']) #Put all patient session in calender mode(To have a sorted data set that gives all patients id's with the dates).\n",
    "    .assign(pain_delta=lambda d: (d.groupby('patient_id')['pain_level'].diff() #Create a new column to help save change in new pain level(transform/standardize the sorted data, assigning a particulae condition(lambda) to new columns with the diff.)\n",
    "    ))\n",
    "    .groupby('patient_id') #Group by patient_id, (collect all the rows belonging to each patient)\n",
    "    .agg(\n",
    "        n_sessions = ('session_id', 'count'), # Defining extra insightss into the session data\n",
    "        avg_session_duration = ('duration', 'mean'),\n",
    "        first_week = ('week', 'min'),\n",
    "        last_week = ('week', 'max'),\n",
    "        mean_pain = ('pain_level', 'mean'),\n",
    "        mean_pain_level_delta = ('pain_delta', 'mean'),\n",
    "        home_adherence_mean = ('home_adherence_pc', 'mean'),\n",
    "        satisfaction_mean = ('satisfaction', 'mean')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f3902",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_agg.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define patients (a static data i.e informations about patient that does not change around segmenting the data\n",
    "patient_sel = patients_df.set_index('patient_id')\n",
    "patient_sel.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the static and dynamic dataset together (For behavioural feature)\n",
    "patient_session_df = patient_sel.join(sess_agg, how='left')\n",
    "patient_session_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5035f",
   "metadata": {},
   "source": [
    "#### Augment the `patient_session_df` with more datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc617e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_flags_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be68385",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling data, (engineering and encoding) Reason is for encoding\n",
    "\n",
    "# Patient static attributes, defines what describe the patient.\n",
    "patient_sel = patients_df[\n",
    "    [\"patient_id\",\n",
    "    \"age\",\n",
    "    \"gender\",\n",
    "    \"bmi\",\n",
    "    \"smoker\",\n",
    "    \"chronic_cond\",\n",
    "    \"injury_type\",\n",
    "    \"referral_source\",\n",
    "    \"insurance_type\"\n",
    "    ]\n",
    "].set_index(\"patient_id\")\n",
    "\n",
    "# Label Engineering (attache the dropout_flags_df to patients)\n",
    "# Label will be use as source of truth later in prediction (who dropped out or not)\n",
    "\n",
    "# Do the labels; to know who the data said dropout durring the sesion, to know why.\n",
    "label = dropout_flags_df.set_index(\"patient_id\").dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_session_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c39f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_session_df.select_dtypes(include='number').corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient_session_df.select_dtypes(include='number').corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = patient_session_df.select_dtypes(include='number').corr()\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix â€” Numeric Features Only', fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Dimension reduction, this is as a result of Correllation Analysis\n",
    "\n",
    "# Define Data Pipeline - Compress all data processing step into one pipeline\n",
    "\n",
    "# - Define numeric Columns and Categorical Columns.\n",
    "\n",
    "# Look out for high dimensions in the data\n",
    "# Lookout for density in the data.\n",
    "\n",
    "num_cols = [  # ensure to use correlation analysis to guide choice of features.\n",
    "    \"age\", \"bmi\",\n",
    "    \"n_sessions\", \"avg_session_duration\", \n",
    "    \"mean_pain\", \"mean_pain_level_delta\"\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    \"gender\", \"smoker\", \n",
    "    \"chronic_cond\", \"injury_type\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_session_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_session_df[cat_cols].astype(\"string\")  # casting categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121b4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient_session_df[num_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing the pipeline(to help compress...)\n",
    "\n",
    "numeric_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scalar\", RobustScaler())\n",
    "    ]\n",
    ")\n",
    "categorical_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Transformer, # Apply the pipeline and transform everthing\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, num_cols),\n",
    "        (\"cat\", categorical_pipe, cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(type(preprocess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92976978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model the data\n",
    "X_preprocess = preprocess.fit_transform(patient_session_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9fb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto dimension reduction;  the Concept used is the PCA\n",
    "\n",
    "# PCA to help retain the variance of features while reducing the dimensionality of data\n",
    "pca = PCA(n_components=0.85, random_state=42) # n_components i.e number of components is the percent of variance to maintain\n",
    "\n",
    "# Attache the PCA to the data into a new data, to result to reduced variance.\n",
    "X_reduced = pca.fit_transform(X_preprocess)\n",
    "X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f620fc",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "X_reduced is now a properly cleaned data, hence we choose the algorithm, to sample either of:\n",
    "- K-means\n",
    "- Hierarchical clustering\n",
    "- DBSCAN\n",
    "- HBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd53c1",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "- Define K-means; then check in the following:\n",
    "    - ELbow\n",
    "    - silhouette_score\n",
    "    - choose k and get cluster\n",
    "    - Do DBSCAN\n",
    "    - PCAN\n",
    "    - Answer Dropout Questions(\"fast_improver\", \"steady progresser\", \"frustrated_droppers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN(Algortithm that is density based): Applying to the X_reduced (cleaned data)\n",
    "\n",
    "# Define the DBSCAN algorithm\n",
    "eps = 1.5           # What should be the Distance between each patient in a cluster...i.e the core points\n",
    "min_samples = 3     # Define the Minimium number of border points i.e surrounding core points\n",
    "db = DBSCAN(eps=eps, min_samples=min_samples).fit(X_reduced)\n",
    "db_labels = db.labels_  # labels -1 are noise points .ie the outliers, far away from core points\n",
    "\n",
    "\n",
    "# filtered valid points or clusters (excluded the noise points)\n",
    "valid_labels = db_labels != -1 # Remove for the one that is the last point...\n",
    "\n",
    "# Now How well are this cluster formed? are they properly formed?,\n",
    "# Check the SILHOUTEE, i.e Check the shape, is it properly shaped?\n",
    "\n",
    "# Calculate the silhoutee score\n",
    "\n",
    "# The Rule of Thumb:\n",
    "# silhoutee score should be between 1, 0, 0r -1;\n",
    "# If score is above 0 and close to 1, cluster in good shape\n",
    "# If score is 0 cluster good but could be improved\n",
    "# If score is below 0 and close to -1 cluster bad and not in good shape\n",
    "\n",
    "\n",
    "# The silhoutee score\n",
    "# Check to see based on eps/min_sample, can a cluster be derived out of the sample?\n",
    "# When atleast a cluster is found, give the silhoutee score.\n",
    "\n",
    "if valid_labels.sum() > 1 :\n",
    "    sil_db = silhouette_score(X_reduced[valid_labels], db_labels[valid_labels])\n",
    "    print(f\"DBSCAN VALID CLUSTER Silhoutee score {sil_db:.3f}\")\n",
    "else:\n",
    "    print(f\"Not enough cluster to be derived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1873f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot DBSCAN\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=db_labels, cmap='viridis', s=50)\n",
    "plt.colorbar(label=\"Cluster ID\")\n",
    "plt.title(\"DBSCAN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aeb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#db = DBSCAN(eps=2.3, min_samples=4).fit(X_reduced)\n",
    "#db_labels = db.labels_\n",
    "#sil_db = silhouette_score(X_reduced[db_labels != -1],\n",
    "                          #db_labels[db_labels != -1])\n",
    "#print(f\"DBSCAN VALID CLUSTER SILHOUTEE: {sil_db:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN -------- catch any extra outliers\n",
    "#knn = NearestNeighbors(n_neighbors=4).fit(X_preprocess)\n",
    "#dists = np.sort(knn.kneighbors(X_preprocess)[0][:,-1])\n",
    "#plt.figure(figsize=(15, 8)); plt.plot(dists, 'o-'); pl \n",
    "# t.title(\"4-NN distance - choose E\"); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47941cc9",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "This shows the data is overlapping \n",
    "The reason is because\n",
    "       - The data does not have equal density, some data are more densed than others.\n",
    "       - The data is not uniformly distributed.e.g age not equally densed...\n",
    "\n",
    "What to do:\n",
    "Use the Kmeans algorithm to group data into meaningful clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de22980",
   "metadata": {},
   "source": [
    "#### Clust_ready = preprocess\n",
    "\n",
    "#### Define k,to group patients into meaningful personas\n",
    "\n",
    "steps:\n",
    "- loop through a range of k (assumptions)\n",
    "- plot the elbow\n",
    "- plot the silhoutee\n",
    "- decision making and choosing of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd86263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_search(X, k_range=range(2, 11)):\n",
    "    wcss = []  # Within-cluster sum of squares\n",
    "    sils = []  # Silhouette scores\n",
    "\n",
    "    for k in k_range:               # loop through the range of k\n",
    "        km = KMeans(\n",
    "            n_clusters=k,\n",
    "            init=\"k-means++\",       # first centroid start apart\n",
    "            n_init=\"auto\",\n",
    "            random_state=42,\n",
    "            algorithm=\"lloyd\"  #  'lloyd'\n",
    "        )\n",
    "        preds = km.fit_predict(X)   # runs the algorithm and returns a cluster id for each patient\n",
    "        wcss.append(km.inertia_)       # Elbows tension inside cluster aka rubber band effect\n",
    "        sils.append(silhouette_score(X, preds))  # 'silhoutte_score' seperate and compact each point \n",
    "\n",
    "    return wcss, sils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598c1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means On the:\n",
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ElbowÂ andÂ silhoutte\n",
    "wcss, sils = k_search(X_reduced)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(wcss)\n",
    "plt.title('ELBOW')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('wcss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf8a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ElbowÂ andÂ silhoutte\n",
    "wcss, sils = k_search(X_reduced)\n",
    "plt.figure(figsize=(15,8)); plt.plot(range(2,11), wcss, 'o-')\n",
    "plt.title('ELBOW')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('wcss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Silhoutee\n",
    "plt.figure(figsize=(15,8)); plt.plot(range(2,11), sils, 'o-')\n",
    "plt.title('SILHOUTEE')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('silhoutee score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule of thumb: pick the smallest k past the elbow and hows silhoutee closer to the KPI (business >=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad26c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose k = k\n",
    "\n",
    "k_OPT = 3\n",
    "k_means = KMeans(\n",
    "    n_clusters=k_OPT,\n",
    "    n_init=\"auto\",\n",
    "    random_state=42,\n",
    "    algorithm=\"lloyd\" \n",
    ")\n",
    "clusters = k_means.fit_predict(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bdb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA/t-SNE visual\n",
    "\n",
    "pca2 = PCA(n_components=2, random_state=42).fit_transform(X_reduced)\n",
    "tsne2 = TSNE(n_components=2, perplexity=40,\n",
    "             init=\"pca\", random_state=42).fit_transform(X_reduced)\n",
    "\n",
    "\n",
    "def scatter_2d(mat, labels, title):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.scatter(mat[:, 0], mat[:, 1], c=labels, alpha=0.6, s=10)\n",
    "    plt.title(title),\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "scatter_2d(pca2, clusters, \"PCA - coloured by K-Means cluster\")\n",
    "scatter_2d(tsne2, clusters, \"t-SNE - coloured by K-Means cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742d1be",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "- PCA (2d dimensional view) shows Proper clusters i.e Optimal clusters\n",
    "- t-SNE(More Zoomed in) shows that clusters distinct, thier still some overlapping clusters... Need optimization to be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "# Save the KMeans model\n",
    "os.makedirs(\"models/saved_models\", exist_ok=True)\n",
    "dump(k_means, \"models/saved_models/kmeans_segmentation.joblib\")\n",
    "\n",
    "# Save the DBSCAN model\n",
    "dump(db, \"models/saved_models/dbscan_segmentation.joblib\")\n",
    "\n",
    "# Save the PCA and TSNE transforms\n",
    "dump(pca2, \"models/saved_models/pca2.joblib\")\n",
    "dump(tsne2, \"models/saved_models/tsne2.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figures\n",
    "os.makedirs(\"reports/figures\", exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(15,8)); plt.plot(range(2,11), wcss, 'o-')\n",
    "plt.title('ELBOW')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('wcss')\n",
    "plt.savefig(\"reports/figures/elbow_plot.png\")\n",
    "\n",
    "plt.figure(figsize=(15,8)); plt.plot(range(2,11), sils, 'o-')\n",
    "plt.title('SILHOUETTE')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('score')\n",
    "plt.savefig(\"reports/figures/silhouette_plot.png\")\n",
    "\n",
    "scatter_2d(pca2, clusters, \"PCA - coloured by K-Means cluster\")\n",
    "plt.savefig(\"reports/figures/pca_clusters.png\")\n",
    "\n",
    "scatter_2d(tsne2, clusters, \"t-SNE - coloured by K-Means cluster\")\n",
    "plt.savefig(\"reports/figures/tsne_clusters.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08eec4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936ee3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ffe57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44cfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b060054b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36397a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aca908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
