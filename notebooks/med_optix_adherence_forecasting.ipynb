{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5ba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install boto3\n",
    "%pip install psycopg2\n",
    "%pip install sqlalchemy\n",
    "%pip install dotenv\n",
    "\n",
    "\n",
    "%pip matplotlib\n",
    "%pip plotly\n",
    "%pip seaborn \n",
    "\n",
    "\n",
    "# Run this cell to install these packages\n",
    "# !pip install pandas boto3 sqlalchemy python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af5a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder,  StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "#  Model Comparison \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "# --- Regression Models ---\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import shap\n",
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ea2e9",
   "metadata": {},
   "source": [
    "# <h2 align=\"center\">Data Input</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c510ed6",
   "metadata": {},
   "source": [
    "### Define a Function to Query & Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5408b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to fetch data from the database\n",
    "def get_db_connection():\n",
    "    db_url = (\n",
    "        f\"postgresql://{os.environ['DB_USER']}:{os.environ['DB_PASSWORD']}@\"\n",
    "        f\"{os.environ['DB_HOST']}:{os.environ['DB_PORT']}/{os.environ['DB_NAME']}\"\n",
    "    )\n",
    "    return create_engine(db_url)\n",
    "\n",
    "# Instantiate the database connection\n",
    "engine = get_db_connection()\n",
    "\n",
    "\n",
    "# Define query to fetch data from each table\n",
    "query_clinics = \"SELECT * FROM clinics;\"\n",
    "query_patients = \"SELECT * FROM patients;\"\n",
    "query_sessions = \"SELECT * FROM sessions;\"\n",
    "query_feedback = \"SELECT * FROM feedback;\"\n",
    "query_dropout_flags = \"SELECT * FROM dropout_flags;\"\n",
    "query_interventions = \"SELECT * FROM interventions;\"\n",
    "\n",
    "# Load data from each table into a DataFrame\n",
    "clinics_df = pd.read_sql(query_clinics, engine)\n",
    "patients_df = pd.read_sql(query_patients, engine)\n",
    "sessions_df = pd.read_sql(query_sessions, engine)\n",
    "feedback_df = pd.read_sql(query_feedback, engine)\n",
    "dropout_flags_df = pd.read_sql(query_dropout_flags, engine)\n",
    "interventions_df = pd.read_sql(query_interventions, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. EDA: Data Overview\n",
    "\n",
    "print(\"clinics_df:\", clinics_df.shape)\n",
    "print(clinics_df.head())\n",
    "print(\"patients_df:\", patients_df.shape)\n",
    "print(patients_df.head())\n",
    "print(\"sessions_df:\", sessions_df.shape)\n",
    "print(sessions_df.head())\n",
    "print(\"feedback_df:\", feedback_df.shape)\n",
    "print(feedback_df.head())\n",
    "print(\"dropout_flags_df:\", dropout_flags_df.shape)\n",
    "print(dropout_flags_df.head())\n",
    "print(\"interventions_df:\", interventions_df.shape)\n",
    "print(interventions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Data Overview ---\n",
    "print(\"clinics_df:\", clinics_df.shape)\n",
    "print(\"patients_df:\", patients_df.shape)\n",
    "print(\"sessions_df:\", sessions_df.shape)\n",
    "print(\"feedback_df:\", feedback_df.shape)\n",
    "print(\"dropout_flags_df:\", dropout_flags_df.shape)\n",
    "print(\"interventions_df:\", interventions_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b125d28",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "- Create New features\n",
    "- Merge relevant datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0f7692",
   "metadata": {},
   "source": [
    "## NOTE: \n",
    "After the EDA, the data is pretty messy, hence we will:\n",
    "- define the `patients data and session data` and merge the data together followed by, \n",
    "- creating a pipeline (define numerical and categorical columns),\n",
    "- Then preprocessing the data before doing the clustering,\n",
    "- Then do the clustering,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d5085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session Aggregation (Dynamic Features)\n",
    "sess_agg = (\n",
    "    sessions_df\n",
    "    .sort_values(['patient_id', 'date'])\n",
    "    .assign(\n",
    "        pain_delta=lambda d: d.groupby('patient_id')['pain_level'].diff(),\n",
    "        session_gap=lambda d: d.groupby('patient_id')['date'].diff().dt.days\n",
    "    )\n",
    "    .groupby('patient_id')\n",
    "    .agg(\n",
    "        n_sessions=('session_id', 'count'),\n",
    "        avg_session_duration=('duration', 'mean'),\n",
    "        first_week=('week', 'min'),\n",
    "        last_week=('week', 'max'),\n",
    "        mean_pain=('pain_level', 'mean'),\n",
    "        mean_pain_delta=('pain_delta', 'mean'),\n",
    "        max_pain_delta=('pain_delta', 'max'),\n",
    "        min_pain_delta=('pain_delta', 'min'),\n",
    "        std_pain_delta=('pain_delta', 'std'),\n",
    "        home_adherence_mean=('home_adherence_pc', 'mean'),\n",
    "        home_adherence_std=('home_adherence_pc', 'std'),\n",
    "        satisfaction_mean=('satisfaction', 'mean'),\n",
    "        avg_session_gap=('session_gap', 'mean'),\n",
    "        missed_sessions=('session_gap', lambda x: (x > 7).sum())\n",
    "    )\n",
    ")\n",
    "print(\"sess_agg shape:\", sess_agg.shape)\n",
    "print(sess_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e621f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3388a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_agg.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bdf4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adherence_class from home_adherence_mean in sess_agg, then drop home_adherence_mean\n",
    "\n",
    "# Bin as percentage\n",
    "bins = [-1, 40, 60, np.inf]  # <60%: Low, 60-85%: Medium, >85%: High\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "sess_agg['adherence_class'] = pd.cut(sess_agg['home_adherence_mean'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8517d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_agg.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b107152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ec756",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_agg.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977175e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adherence class distribution:\")\n",
    "print(sess_agg['adherence_class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487918c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aggregate feedback data (sentiment, if available)\n",
    "if 'sentiment' in feedback_df.columns:\n",
    "    feedback_agg = (\n",
    "        feedback_df\n",
    "        .merge(sessions_df[['session_id', 'patient_id']], on='session_id', how='left')\n",
    "        .groupby('patient_id')\n",
    "        .agg(\n",
    "            feedback_sentiment_mean=('sentiment', 'mean'),\n",
    "            feedback_sentiment_std=('sentiment', 'std'),\n",
    "            feedback_count=('sentiment', 'count')\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    feedback_agg = pd.DataFrame()\n",
    "print(\"feedback_agg shape:\", feedback_agg.shape)\n",
    "print(feedback_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Aggregate interventions (count and type)\n",
    "intervention_agg = (\n",
    "    interventions_df\n",
    "    .groupby('patient_id')\n",
    "    .agg(\n",
    "        n_interventions=('intervention_id', 'count'),\n",
    "        unique_interventions=('channel', pd.Series.nunique)\n",
    "    )\n",
    ")\n",
    "print(\"intervention_agg shape:\", intervention_agg.shape)\n",
    "print(intervention_agg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55199cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge All Features\n",
    "patient_static = patients_df.set_index('patient_id')\n",
    "features = patient_static.join(sess_agg, how='left')\n",
    "if not feedback_agg.empty:\n",
    "    features = features.join(feedback_agg, how='left')\n",
    "features = features.join(intervention_agg, how='left')\n",
    "\n",
    "print(\"Final feature set shape:\", features.shape)\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11197db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8df68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Selection & Preprocessing\n",
    "\n",
    "# --- Select Features ---\n",
    "num_cols = [\n",
    "    \"age\", \"bmi\", \"n_sessions\", \"avg_session_duration\", \"mean_pain\", \"mean_pain_delta\",\n",
    "    \"max_pain_delta\", \"min_pain_delta\", \"std_pain_delta\", \"home_adherence_mean\",\n",
    "    \"home_adherence_std\", \"satisfaction_mean\", \"avg_session_gap\", \"missed_sessions\",\n",
    "    \"feedback_sentiment_mean\", \"feedback_sentiment_std\", \"feedback_count\",\n",
    "    \"n_interventions\", \"unique_interventions\"\n",
    "]\n",
    "cat_cols = [\n",
    "    \"gender\", \"smoker\", \"chronic_cond\", \"injury_type\", \"referral_source\", \"insurance_type\"\n",
    "]\n",
    "target_col = \"home_adherence_mean\"\n",
    "\n",
    "# --- Data Cleaning ---\n",
    "features[num_cols] = features[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "features[cat_cols] = features[cat_cols].astype(\"string\")\n",
    "data = features.dropna(subset=[target_col])\n",
    "\n",
    "print(\"Modeling data shape:\", data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be9820",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5958d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix ambiguous NA in 'smoker' column (and any other string/categorical columns)\n",
    "# Replace pd.NA/NA/None with string 'Unknown' before modeling or any boolean operation\n",
    "\n",
    "for col in cat_cols:\n",
    "    data[col] = data[col].astype(\"string\").fillna(\"Unknown\").replace({pd.NA: \"Unknown\", None: \"Unknown\"})\n",
    "\n",
    "# Now you can safely use boolean operations or fit models without TypeError\n",
    "data['smoker'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb71d96",
   "metadata": {},
   "source": [
    "### REGRESSSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8034e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression: Predict Adherence Level (Continuous)\n",
    "\n",
    "X = data[num_cols + cat_cols]\n",
    "y = data[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d069ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocessing Pipeline ---\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, num_cols),\n",
    "    (\"cat\", categorical_pipe, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa43d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42, verbosity=0),\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=0, random_state=42),\n",
    "    \"MLPRegressor\": MLPRegressor(max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in regressors.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(\"R2:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning Example (Random Forest)\n",
    "param_grid = {\n",
    "    \"model__n_estimators\": [100, 200],\n",
    "    \"model__max_depth\": [None, 5, 10]\n",
    "}\n",
    "rf_pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(random_state=42))\n",
    "])\n",
    "grid = GridSearchCV(rf_pipe, param_grid, scoring='neg_mean_absolute_error', cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"\\nBest Random Forest Params:\", grid.best_params_)\n",
    "best_rf = grid.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "print(\"Tuned Random Forest MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "rmse = mse ** 0.5\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"Tuned Random Forest R2:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73450726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual for regression models\n",
    "for name, model in regressors.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.xlabel(\"Actual home_adherence_mean\")\n",
    "    plt.ylabel(\"Predicted home_adherence_mean\")\n",
    "    plt.title(f\"{name}: Actual vs Predicted\")\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebdf073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tuned random forest regression model\n",
    "joblib.dump(best_rf, \"models/saved_models/best_random_forest_regressor.joblib\")\n",
    "\n",
    "# SHAP plot for regressor\n",
    "try:\n",
    "    explainer = shap.Explainer(best_rf.named_steps[\"model\"], best_rf.named_steps[\"preprocessor\"].transform(X_test))\n",
    "    shap_values = explainer(best_rf.named_steps[\"preprocessor\"].transform(X_test))\n",
    "    shap.summary_plot(shap_values, feature_names=best_rf.named_steps[\"preprocessor\"].get_feature_names_out(), show=False)\n",
    "    plt.title(\"SHAP Summary: Random Forest Regressor\")\n",
    "    plt.savefig(\"reports/figures/shap_rf_regressor.png\")\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(f\"SHAP failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f22c8f",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734478f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a896f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the home_adherence_mean column\n",
    "features = features.drop(columns=['home_adherence_mean'])\n",
    "\n",
    "features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1d596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Feature Selection & Preprocessing\n",
    "\n",
    "# Select Features \n",
    "num_cols = [\n",
    "    \"age\", \"bmi\", \"n_sessions\", \"avg_session_duration\", \"mean_pain\", \"mean_pain_delta\",\n",
    "    \"max_pain_delta\", \"min_pain_delta\", \"std_pain_delta\",\n",
    "    \"home_adherence_std\", \"satisfaction_mean\", \"avg_session_gap\", \"missed_sessions\",\n",
    "    \"feedback_sentiment_mean\", \"feedback_sentiment_std\", \"feedback_count\",\n",
    "    \"n_interventions\", \"unique_interventions\"\n",
    "]\n",
    "cat_cols = [\n",
    "    \"gender\", \"smoker\", \"chronic_cond\", \"injury_type\", \"referral_source\", \"insurance_type\"\n",
    "]\n",
    "target_col = \"adherence_class\"\n",
    "\n",
    "# --- Data Cleaning ---\n",
    "features[num_cols] = features[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "features[cat_cols] = features[cat_cols].astype(\"string\")\n",
    "data = features.dropna(subset=[target_col])\n",
    "\n",
    "print(\"Modeling data shape:\", data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8111b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Cleaning ---\n",
    "features[num_cols] = features[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "features[cat_cols] = features[cat_cols].astype(\"string\")\n",
    "data = features.dropna(subset=[target_col])\n",
    "\n",
    "# Replace ambiguous NA in categorical columns with 'Unknown'\n",
    "for col in cat_cols:\n",
    "    data[col] = data[col].astype(\"string\").fillna(\"Unknown\").replace({pd.NA: \"Unknown\", None: \"Unknown\"})\n",
    "\n",
    "# Fill numeric columns with median to avoid NaN\n",
    "for col in num_cols:\n",
    "    data[col] = data[col].fillna(data[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection using RandomForest for importance ranking\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical columns for feature selection\n",
    "data_fs = data.copy()\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    data_fs[col] = le.fit_transform(data_fs[col].astype(str))\n",
    "\n",
    "# Encode target\n",
    "le_target = LabelEncoder()\n",
    "y_fs = le_target.fit_transform(data_fs[target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1473a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit RandomForest to get feature importances\n",
    "rf_fs = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_fs.fit(data_fs[num_cols + cat_cols], y_fs)\n",
    "importances = rf_fs.feature_importances_\n",
    "\n",
    "# Select top features (e.g., top 10)\n",
    "import numpy as np\n",
    "feature_names = num_cols + cat_cols\n",
    "top_idx = np.argsort(importances)[::-1][:10]\n",
    "selected_features = [feature_names[i] for i in top_idx]\n",
    "print(\"Top features for classification:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for classification\n",
    "X_cls = data[selected_features]\n",
    "y_cls = data[target_col]\n",
    "\n",
    "# Encode categorical columns in X_cls for SMOTE\n",
    "X_cls_enc = X_cls.copy()\n",
    "for col in X_cls_enc.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X_cls_enc[col] = le.fit_transform(X_cls_enc[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b59295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
    "    X_cls_enc, y_cls, stratify=y_cls, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e52f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for selected features\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_selected = [col for col in selected_features if col in num_cols]\n",
    "cat_selected = [col for col in selected_features if col in cat_cols]\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, num_selected),\n",
    "    (\"cat\", categorical_pipe, cat_selected)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8567db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target for SMOTE\n",
    "le_y = LabelEncoder()\n",
    "y_train_cls_enc = le_y.fit_transform(y_train_cls)\n",
    "\n",
    "# Preprocess X_train for SMOTE (must be numeric)\n",
    "X_train_for_smote = preprocessor.fit_transform(X_train_cls)\n",
    "# Convert to DataFrame for SMOTE compatibility\n",
    "import pandas as pd\n",
    "X_train_for_smote = pd.DataFrame(X_train_for_smote)\n",
    "\n",
    "# Balance classes with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_cls_bal, y_train_cls_bal = smote.fit_resample(X_train_for_smote, y_train_cls_enc)\n",
    "\n",
    "# Prepare X_test for evaluation\n",
    "X_test_for_eval = preprocessor.transform(X_test_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n",
    "    \"MLPClassifier\": MLPClassifier(max_iter=500, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab88e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in classifiers.items():\n",
    "    # Fit on balanced data\n",
    "    model.fit(X_train_cls_bal, y_train_cls_bal)\n",
    "    # Predict on test set (need to encode y_test for report)\n",
    "    y_pred = model.predict(X_test_for_eval)\n",
    "    y_test_cls_enc = le_y.transform(y_test_cls)\n",
    "    print(f\"\\n{name}\")\n",
    "    print(classification_report(y_test_cls_enc, y_pred, target_names=le_y.classes_))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_cls_enc, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Encode target labels as integers for classification\n",
    "le_y = LabelEncoder()\n",
    "y_train_cls_enc = le_y.fit_transform(y_train_cls)\n",
    "y_test_cls_enc = le_y.transform(y_test_cls)\n",
    "\n",
    "# Define parameter grids for each model\n",
    "param_grids = {\n",
    "    \"Random Forest\": {\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [None, 5, 10]\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        \"model__C\": [0.1, 1, 10],\n",
    "        \"model__solver\": [\"lbfgs\", \"liblinear\"]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [3, 5, 7]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        \"model__iterations\": [100, 200],\n",
    "        \"model__depth\": [4, 6, 8]\n",
    "    },\n",
    "    \"MLPClassifier\": {\n",
    "        \"model__hidden_layer_sizes\": [(50,), (100,)],\n",
    "        \"model__alpha\": [0.0001, 0.001]\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "for name, model in classifiers.items():\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    param_grid = param_grids.get(name, {})\n",
    "    grid = GridSearchCV(pipe, param_grid, scoring='f1_weighted', cv=3, n_jobs=-1)\n",
    "    grid.fit(X_train_cls, y_train_cls_enc)\n",
    "    best_models[name] = grid.best_estimator_\n",
    "    y_pred = best_models[name].predict(X_test_cls)\n",
    "    print(f\"\\n{name} (Best Params: {grid.best_params_})\")\n",
    "    print(classification_report(y_test_cls_enc, y_pred, target_names=le_y.classes_))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test_cls_enc, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4279f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix display and save models\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test_cls)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test_cls_enc, y_pred, display_labels=le_y.classes_\n",
    "    )\n",
    "    plt.title(f\"{name} Best Model Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a96413",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models/saved_models\", exist_ok=True)\n",
    "os.makedirs(\"reports/figures\", exist_ok=True)\n",
    "\n",
    "# Save classification models\n",
    "for name, model in best_models.items():\n",
    "    file_path = f\"models/saved_models/{name.replace(' ', '_').lower()}_best_classifier.joblib\"\n",
    "    joblib.dump(model, file_path)\n",
    "    print(f\"Saved {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d0c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Feature Importance for all best classification models\n",
    "for name, model in best_models.items():\n",
    "    # Get the model from the pipeline\n",
    "    clf = model.named_steps[\"model\"]\n",
    "    # Get preprocessed test data\n",
    "    X_test_transformed = model.named_steps[\"preprocessor\"].transform(X_test_cls)\n",
    "    # SHAP expects a model, not a pipeline\n",
    "    try:\n",
    "        explainer = shap.Explainer(clf, X_test_transformed)\n",
    "        shap_values = explainer(X_test_transformed)\n",
    "        plt.figure()\n",
    "        shap.summary_plot(shap_values, X_test_transformed, feature_names=model.named_steps[\"preprocessor\"].get_feature_names_out())\n",
    "        plt.title(f\"SHAP Summary for {name}\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"SHAP not supported for {name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save SHAP plots for classifiers\n",
    "for name, model in best_models.items():\n",
    "    try:\n",
    "        clf = model.named_steps[\"model\"]\n",
    "        X_test_transformed = model.named_steps[\"preprocessor\"].transform(X_test_cls)\n",
    "        explainer = shap.Explainer(clf, X_test_transformed)\n",
    "        shap_values = explainer(X_test_transformed)\n",
    "        shap.summary_plot(shap_values, X_test_transformed, \n",
    "                          feature_names=model.named_steps[\"preprocessor\"].get_feature_names_out(), \n",
    "                          show=False)\n",
    "        plt.title(f\"SHAP Summary: {name}\")\n",
    "        plt.savefig(f\"reports/figures/shap_{name.replace(' ', '_').lower()}_cls.png\")\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"SHAP not supported for {name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medoptix_ai_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
